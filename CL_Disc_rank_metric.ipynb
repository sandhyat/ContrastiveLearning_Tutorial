{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30344c98",
   "metadata": {},
   "source": [
    "\n",
    "# Contrastive learning as an instance discriminator with a rank metric\n",
    "\n",
    "This file contains code to demonstrate how contrastive learning is effectively an instance discrimination problem.\n",
    "In particular, we present a similarity rank based metric that can determine the difficulty of the instance discrimination task.\n",
    "\n",
    "The metric is computed as follows:\n",
    "1) The similarity matrix for each batch is ranked row wise. In our setup, the highest similarity value between the representation of the two augmentations is the largest rank.\n",
    "\n",
    "2) Compute the trace of the ranked simialrity matrix. Since, diagonal of the similarity matrix refers to a positive pair, for better learning we would expect the diagonal values of the rank matrix to be higher. \n",
    "\n",
    "3) Compute Trace/batchsize which gives average rank of a positive pair.\n",
    "\n",
    "We use openly available public dataset [Nomao](https://archive.ics.uci.edu/dataset/227/nomao) and are interested in learning contrastive loss based data representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "86b05119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing packages\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import svm, linear_model, model_selection, metrics, ensemble\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, pairwise,mutual_info_score,mean_squared_error\n",
    "from scipy import linalg, stats\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from matching.games import StableMarriage\n",
    "import pingouin as pg\n",
    "import datetime\n",
    "# from datetime import datetime\n",
    "import json, sys, argparse\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# import requests\n",
    "# from transformers import CLIPProcessor, CLIPModel\n",
    "# from PIL import Image\n",
    "# from datasets import load_dataset\n",
    "# import torchvision.datasets as dset\n",
    "# import torchvision.transforms as transforms\n",
    "# import base64\n",
    "# import io\n",
    "# from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d790b3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for computing the contrastive loss and the similarity metric\n",
    "def NTXentLoss(z1, z2,\n",
    "                 temperature=0.1): \n",
    "    # compute the cosine similarity but first normalizing and then matrix multiplying the known and unknown tensors\n",
    "    cos_sim_o = torch.div(torch.matmul(torch.nn.functional.normalize(z1),\n",
    "                                       torch.transpose(torch.nn.functional.normalize(z2), 0, 1)),\n",
    "                          temperature)\n",
    "\n",
    "    # for numerical stability  ## TODO update this logit name\n",
    "    logits_max_o, _ = torch.max(cos_sim_o, dim=1, keepdim=True)\n",
    "    logits_o = cos_sim_o - logits_max_o.detach()\n",
    "\n",
    "    # breakpoint()\n",
    "    if True:\n",
    "      # computing the exp logits\n",
    "      exp_o = torch.exp(logits_o)\n",
    "      batch_loss_o = - torch.log(exp_o.diag() / exp_o.sum(dim=0)).sum() - torch.log(\n",
    "        exp_o.diag() / exp_o.sum(dim=1)).sum()\n",
    "      # computing the avg rank of the positive examples for checking if the algo is learning the representation closer\n",
    "      # since we are computing the rank on the similarity so higher the better\n",
    "      avg_rank_cos_sim_o = np.trace(stats.rankdata(cos_sim_o.cpu().detach().numpy(), axis=1)) / len(cos_sim_o)\n",
    "\n",
    "    # print(\"This batch's loss and avg rank \", batch_loss_o.item(), batch_loss_r.item(), avg_rank_cos_sim_o, avg_rank_cos_sim_r)\n",
    "    return batch_loss_o, avg_rank_cos_sim_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7ede3900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for initial loading and processing of the dataset\n",
    "def load_dataset(dataset):\n",
    "    if dataset=='SD_2':\n",
    "        filename = \"2021-05-18Syn_Data_2_Sample_no_1_size_20_10000_for_AE_balanced.csv\" \n",
    "        data_file = os.path.join('./Small_datasets', dataset, filename)\n",
    "        full_Data0 = pd.read_csv(data_file)\n",
    "        \n",
    "    if dataset=='Nomao':\n",
    "        data_file = os.path.join('./Small_datasets', dataset, dataset + \".data\")\n",
    "\n",
    "        full_Data0 = pd.read_csv(data_file, header=None)\n",
    "        full_Data0.replace('?', np.nan, inplace=True)\n",
    "        full_Data0 = full_Data0.loc[:, ~(full_Data0 == 'n').any()]  # dropping the nominal type columns\n",
    "        full_Data0.drop(columns=[0], inplace=True)  # dropping the id column\n",
    "\n",
    "        # drop columns with very high missing percentage\n",
    "        percent_missing = full_Data0.isnull().sum() * 100 / len(full_Data0)\n",
    "        missing_value_df = pd.DataFrame({'column_name': full_Data0.columns,\n",
    "                                         'percent_missing': percent_missing}).sort_values(by='percent_missing')\n",
    "        full_Data0 = full_Data0[missing_value_df[missing_value_df['percent_missing'] < 70.0]['column_name']]\n",
    "\n",
    "        ## final columns that were selected including the label and excluding the first column that was the id\n",
    "        ## [1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 65, 66, 67, 68, 69,\n",
    "        # 70, 73, 74, 75, 76, 77, 78, 81, 82, 83, 84, 85, 86, 89, 90, 91, 97, 98, 99, 101, 102, 103, 105, 106, 107, 109,\n",
    "        # 110, 111, 113, 114, 115, 117, 118, 119]\n",
    "\n",
    "        full_Data0 = full_Data0.reindex(columns=sorted(full_Data0.columns))  # reindexing so that label is at the end\n",
    "        new_feature_names = ['Col' + str(i + 1) for i in range(full_Data0.shape[1] - 1)] \n",
    "        full_Data0 = full_Data0.set_axis(new_feature_names+ ['Y'], axis=1)  # renamed the continuous columns\n",
    "\n",
    "        # converting the columns that are being treated as object type but actually are float\n",
    "        for a in full_Data0.columns:\n",
    "            if full_Data0[a].dtype == 'object':\n",
    "                full_Data0[a] = full_Data0[a].astype('float')\n",
    "\n",
    "        full_Data0 = full_Data0.fillna(full_Data0.mean())  # filling the missing values\n",
    "    \n",
    "    full_Data = full_Data0.copy()\n",
    "    full_Data['Y'] = np.where(full_Data['Y'] == -1, 0, 1)  # to make it compatible with the rest    \n",
    "    num_sample = full_Data.shape[0]\n",
    "    num_features = full_Data.shape[1] - 1\n",
    "\n",
    "    # full data initial correlation\n",
    "    Feature_matrix = full_Data.iloc[:, :-1]\n",
    "    Cor_from_df = Feature_matrix.corr()\n",
    "    \n",
    "    return full_Data, num_sample, num_features, Cor_from_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9b63d156",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, data, output_col=None):\n",
    "        \"\"\"\n",
    "        Characterizes a Dataset for PyTorch\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        data: pandas data frame\n",
    "          The data frame object for the input data. It must\n",
    "          contain all the continuous, categorical and the\n",
    "          output columns to be used.\n",
    "\n",
    "        cat_cols: List of strings\n",
    "          The names of the categorical columns in the data.\n",
    "          These columns will be passed through the embedding\n",
    "          layers in the model. These columns must be\n",
    "          label encoded beforehand.\n",
    "\n",
    "        output_col: string\n",
    "          The name of the output variable column in the data\n",
    "          provided.\n",
    "        \"\"\"\n",
    "\n",
    "        self.n = data.shape[0]\n",
    "\n",
    "        if output_col:\n",
    "            self.y = data[output_col].astype(np.float32).values.reshape(-1, 1)\n",
    "        else:\n",
    "            self.y = np.zeros((self.n, 1))\n",
    "\n",
    "        # self.cat_cols = cat_cols if cat_cols else []\n",
    "        self.cont_cols = [col for col in data.columns\n",
    "                          if col not in [output_col]]\n",
    "        # print(self.cont_cols)\n",
    "\n",
    "        if self.cont_cols:\n",
    "            self.cont_X = data[self.cont_cols].astype(np.float32).values\n",
    "        else:\n",
    "            self.cont_X = np.zeros((self.n, 1))\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Denotes the total number of samples.\n",
    "        \"\"\"\n",
    "        return self.n\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Generates one sample of data.\n",
    "        \"\"\"\n",
    "        return [self.y[idx], self.cont_X[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e7692d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_noisy_xbar(x, noise_type=\"Zero-out\", noise_level=0.1):\n",
    "  \"\"\"Generates noisy version of the samples x; Noise types: Zero-out, Gaussian, or Swap noise\n",
    "\n",
    "  Args:\n",
    "      x (np.ndarray): Input data to add noise to\n",
    "\n",
    "  Returns:\n",
    "      (np.ndarray): Corrupted version of input x\n",
    "\n",
    "  \"\"\"\n",
    "  # Dimensions\n",
    "  no, dim = x.shape\n",
    "  # Initialize corruption array\n",
    "  x_bar = torch.zeros_like(x)\n",
    "\n",
    "  # Randomly (and column-wise) shuffle data\n",
    "  if noise_type == \"swap_noise\":\n",
    "    for i in range(dim):\n",
    "      idx = torch.randperm(no)\n",
    "      x_bar[:, i] = x[idx, i]\n",
    "  # Elif, overwrite x_bar by adding Gaussian noise to x\n",
    "  elif noise_type == \"gaussian_noise\":\n",
    "    # breakpoint()\n",
    "    x_bar = x + torch.normal(0, noise_level, size=x.shape, device='cuda')\n",
    "  else:\n",
    "    x_bar = x_bar\n",
    "\n",
    "  return x_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "bbadc84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder networks\n",
    "class MLP(torch.nn.Sequential):\n",
    "    \"\"\"Simple multi-layer perceptron with ReLu activation and optional dropout layer\"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, n_layers, dropout=0.0):\n",
    "        layers = []\n",
    "        in_dim = input_dim\n",
    "        for _ in range(n_layers - 1):\n",
    "            layers.append(torch.nn.Linear(in_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "            layers.append(torch.nn.Dropout(dropout))\n",
    "            in_dim = hidden_dim\n",
    "\n",
    "        layers.append(torch.nn.Linear(in_dim, hidden_dim))\n",
    "\n",
    "        super().__init__(*layers)\n",
    "        \n",
    "class CL_model(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        emb_dim,\n",
    "        encoder_depth=4,\n",
    "        head_depth=2,\n",
    "    ):\n",
    "        \"\"\"Implementation of a SimCLR kind basic CL approach.\n",
    "        It consists of an encoder that learns the embeddings.\n",
    "        It is done by minimizing the contrastive loss of a sample and an augmented view of it.\n",
    "            Args:\n",
    "                input_dim (int): size of the inputs\n",
    "                emb_dim (int): dimension of the embedding space\n",
    "                encoder_depth (int, optional): number of layers of the encoder MLP. Defaults to 4.\n",
    "                head_depth (int, optional): number of layers of the pretraining head. Defaults to 2.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        self.encoder = MLP(input_dim, emb_dim, encoder_depth)\n",
    "        self.pretraining_head = MLP(emb_dim, emb_dim, head_depth)\n",
    "\n",
    "        # initialize weights\n",
    "        self.encoder.apply(self._init_weights)\n",
    "        self.pretraining_head.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.xavier_uniform_(module.weight)\n",
    "            module.bias.data.fill_(0.01)\n",
    "            \n",
    "    def forward(self,x):\n",
    "        rep = self.encoder(x)\n",
    "        proj = self.pretraining_head(rep)\n",
    "        return rep, proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e555443d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial setting and the dataset choice\n",
    "\n",
    "dataset = \"Nomao\" # dataset name  {'SD_2', 'Nomao'}\n",
    "batchSize = 64\n",
    "learningRate = 0.0004\n",
    "LRPatience = 5\n",
    "learningRateFactor=0.3931\n",
    "dropout_rate_CL = 0.1278\n",
    "epochs = 50\n",
    "masking_ratio = 0.1306\n",
    "tau = 0.1893\n",
    "randomSeed = 784  # random seed\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "enc_depth = 5\n",
    "proj_depth = 4\n",
    "Embedding_dim= 15\n",
    "outcome = 'Y'\n",
    "\n",
    "saving_dir = '/home/trips/ContrastiveLearning_Tutorial/Rank_Figures/'\n",
    "if not os.path.exists(saving_dir):\n",
    "    os.makedirs(saving_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "fc57ee67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3027269/2349951105.py:11: DtypeWarning: Columns (57,58,59,60,61,62,65,66,67,68,69,70,101,102,103,105,106,107,117) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  full_Data0 = pd.read_csv(data_file, header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original data size :   (34465, 63)\n"
     ]
    }
   ],
   "source": [
    "# loading data\n",
    "full_data, num_sample, num_features, Cor_from_df = load_dataset(dataset)\n",
    "\n",
    "# data dimensions \n",
    "print(\" Original data size :  \", full_data.shape)  # Number of samples *  number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b21967a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping a holdout sample aside\n",
    "Df_for_training, Df_holdout = model_selection.train_test_split(full_data, test_size=0.2,\n",
    "                                                        random_state=42,\n",
    "                                                        stratify=full_data[outcome])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533db5c2",
   "metadata": {},
   "source": [
    "## Training prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "80cf76a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#explicitly setting the nworkers in the dataloader was incompatible with the jupyter kernel\n",
    "dataset_orig = TabularDataset(data=Df_for_training, output_col=outcome)\n",
    "train_loader_orig = DataLoader(dataset_orig, batchSize, shuffle=True)\n",
    "dataset_orig_val = TabularDataset(data=Df_holdout, output_col=outcome)\n",
    "val_loader_orig = DataLoader(dataset_orig_val, batchSize, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1f5e548b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CL_model(input_dim=num_features,emb_dim=Embedding_dim).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learningRate, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=LRPatience, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb63dd5a",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06a9a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation performance epoch : 1/50, loss_o = 434.96180,  avgbatchwise_rank_o = 52.62734\n",
      "Validation performance epoch : 2/50, loss_o = 431.55502,  avgbatchwise_rank_o = 53.18721\n",
      "Validation performance epoch : 3/50, loss_o = 394.86503,  avgbatchwise_rank_o = 55.90859\n",
      "Validation performance epoch : 4/50, loss_o = 415.02502,  avgbatchwise_rank_o = 55.25226\n",
      "Validation performance epoch : 5/50, loss_o = 388.18207,  avgbatchwise_rank_o = 56.64413\n",
      "Validation performance epoch : 6/50, loss_o = 366.42929,  avgbatchwise_rank_o = 57.66443\n",
      "Validation performance epoch : 7/50, loss_o = 369.88381,  avgbatchwise_rank_o = 57.59273\n",
      "Validation performance epoch : 8/50, loss_o = 358.68931,  avgbatchwise_rank_o = 57.79629\n",
      "Validation performance epoch : 9/50, loss_o = 365.44922,  avgbatchwise_rank_o = 57.80345\n",
      "Validation performance epoch : 10/50, loss_o = 360.01618,  avgbatchwise_rank_o = 57.98058\n",
      "Validation performance epoch : 11/50, loss_o = 349.19862,  avgbatchwise_rank_o = 58.12383\n",
      "Validation performance epoch : 12/50, loss_o = 347.73004,  avgbatchwise_rank_o = 58.21817\n",
      "Validation performance epoch : 13/50, loss_o = 345.20722,  avgbatchwise_rank_o = 58.38683\n",
      "Validation performance epoch : 14/50, loss_o = 340.26113,  avgbatchwise_rank_o = 58.64413\n",
      "Validation performance epoch : 15/50, loss_o = 334.54873,  avgbatchwise_rank_o = 58.72342\n",
      "Validation performance epoch : 16/50, loss_o = 333.02052,  avgbatchwise_rank_o = 58.81790\n",
      "Validation performance epoch : 17/50, loss_o = 335.03152,  avgbatchwise_rank_o = 58.67407\n",
      "Validation performance epoch : 18/50, loss_o = 332.37860,  avgbatchwise_rank_o = 58.85514\n",
      "Validation performance epoch : 19/50, loss_o = 334.65430,  avgbatchwise_rank_o = 58.77760\n",
      "Validation performance epoch : 20/50, loss_o = 332.72673,  avgbatchwise_rank_o = 58.89223\n",
      "Validation performance epoch : 21/50, loss_o = 333.75605,  avgbatchwise_rank_o = 58.80301\n",
      "Validation performance epoch : 22/50, loss_o = 332.40253,  avgbatchwise_rank_o = 58.92188\n",
      "Validation performance epoch : 23/50, loss_o = 333.56640,  avgbatchwise_rank_o = 58.85996\n",
      "Validation performance epoch : 24/50, loss_o = 328.44020,  avgbatchwise_rank_o = 58.99051\n",
      "Validation performance epoch : 25/50, loss_o = 328.52957,  avgbatchwise_rank_o = 58.96481\n",
      "Validation performance epoch : 26/50, loss_o = 324.19826,  avgbatchwise_rank_o = 59.19363\n",
      "Validation performance epoch : 27/50, loss_o = 326.96549,  avgbatchwise_rank_o = 58.96437\n",
      "Validation performance epoch : 28/50, loss_o = 326.90249,  avgbatchwise_rank_o = 58.97503\n",
      "Validation performance epoch : 29/50, loss_o = 325.93994,  avgbatchwise_rank_o = 59.02468\n",
      "Validation performance epoch : 30/50, loss_o = 324.38062,  avgbatchwise_rank_o = 59.14749\n",
      "Validation performance epoch : 31/50, loss_o = 327.40628,  avgbatchwise_rank_o = 59.00131\n",
      "Validation performance epoch : 32/50, loss_o = 326.45566,  avgbatchwise_rank_o = 59.05505\n",
      "Epoch 00032: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Validation performance epoch : 33/50, loss_o = 323.10253,  avgbatchwise_rank_o = 59.10602\n",
      "Validation performance epoch : 34/50, loss_o = 322.35277,  avgbatchwise_rank_o = 59.18400\n",
      "Validation performance epoch : 35/50, loss_o = 322.89538,  avgbatchwise_rank_o = 59.10791\n",
      "Validation performance epoch : 36/50, loss_o = 324.13308,  avgbatchwise_rank_o = 59.08411\n",
      "Validation performance epoch : 37/50, loss_o = 325.57064,  avgbatchwise_rank_o = 59.01197\n",
      "Validation performance epoch : 38/50, loss_o = 322.21119,  avgbatchwise_rank_o = 59.18984\n"
     ]
    }
   ],
   "source": [
    "total_perepoch_loss = []\n",
    "total_perepoch_rank = []\n",
    "for epoch in range(epochs):\n",
    "    loss_tr_o = 0\n",
    "    rank_tr_o = 0\n",
    "    counting_flag_for_rank = 0\n",
    "    # computing the representations from the trained encoders\n",
    "    model.train()\n",
    "\n",
    "    for i, data in enumerate(train_loader_orig):\n",
    "        x = data[1].to(device)\n",
    "        x_bar = x\n",
    "        x_bar_noisy = generate_noisy_xbar(x_bar)\n",
    "        # Generate binary mask\n",
    "        mask = torch.tensor(np.random.binomial(1, masking_ratio, x_bar.shape)).to(device)\n",
    "        mask1 = torch.tensor(np.random.binomial(1, masking_ratio, x_bar.shape)).to(device)\n",
    "        # breakpoint()\n",
    "        # Replace selected x_bar features with the noisy ones\n",
    "        x_aug1 = x_bar * (1 - mask) + x_bar_noisy * mask\n",
    "        x_aug2 = x_bar * (1 - mask1) + x_bar_noisy * mask1\n",
    "    \n",
    "#         print(x_aug1.shape)\n",
    "    \n",
    "        _, rep1 = model(x_aug1)\n",
    "        _, rep2 = model(x_aug2)\n",
    "        contrastive_loss_o, avg_Rank_o = NTXentLoss(rep1, rep2, temperature=tau)\n",
    "    \n",
    "        # compute accumulated gradients\n",
    "        contrastive_loss_o.backward()\n",
    "    \n",
    "        # perform parameter update based on current gradients\n",
    "        optimizer.step()\n",
    "    \n",
    "        # add the mini-batch training loss to epoch loss\n",
    "        loss_tr_o += contrastive_loss_o.item()\n",
    "        if (data[1].shape[0] == batchSize):\n",
    "            rank_tr_o += avg_Rank_o.item()\n",
    "            counting_flag_for_rank = counting_flag_for_rank + 1\n",
    "    \n",
    "        # compute the epoch training loss\n",
    "    loss_tr_o = loss_tr_o / (len(train_loader_orig))\n",
    "    rank_tr_o = rank_tr_o / (\n",
    "        counting_flag_for_rank)  # dividing by counting_flag_for_rank because the avg rank from all batches in not included\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # computing the representations from the trained encoders\n",
    "        model.eval()\n",
    "        loss_val_o = 0\n",
    "        rank_val_o = 0\n",
    "        counting_flag_for_rank_val = 0\n",
    "    \n",
    "        for i, data in enumerate(val_loader_orig):\n",
    "            x = data[1].to(device)\n",
    "            x_bar = x\n",
    "            x_bar_noisy = generate_noisy_xbar(x_bar)\n",
    "            # Generate binary mask\n",
    "            mask = torch.tensor(np.random.binomial(1, masking_ratio, x_bar.shape)).to(device)\n",
    "            mask1 = torch.tensor(np.random.binomial(1, masking_ratio, x_bar.shape)).to(device)\n",
    "            # breakpoint()\n",
    "            # Replace selected x_bar features with the noisy ones\n",
    "            x_aug1 = x_bar * (1 - mask) + x_bar_noisy * mask\n",
    "            x_aug2 = x_bar * (1 - mask1) + x_bar_noisy * mask1\n",
    "    \n",
    "            _, rep1 = model(x_aug1)\n",
    "            _, rep2 = model(x_aug2)\n",
    "            contrastive_loss_o, avg_Rank_o = NTXentLoss(rep1, rep2, temperature=tau)\n",
    "    \n",
    "            # add the mini-batch training loss to epoch loss\n",
    "            loss_val_o += contrastive_loss_o.item()\n",
    "            if (data[1].shape[0] == batchSize):\n",
    "                rank_val_o += avg_Rank_o.item()\n",
    "                counting_flag_for_rank_val = counting_flag_for_rank_val + 1\n",
    "            \n",
    "    \n",
    "        # compute the epoch training loss\n",
    "        loss_val_o = loss_val_o / (len(val_loader_orig))\n",
    "        rank_val_o = rank_val_o / (counting_flag_for_rank_val)\n",
    "        total_perepoch_loss.append(loss_val_o)\n",
    "        total_perepoch_rank.append(rank_val_o)\n",
    "    \n",
    "        # display the epoch validation loss\n",
    "        print(\"Validation performance epoch : {}/{}, loss_o = {:.5f},  avgbatchwise_rank_o = {:.5f}\".format(\n",
    "            epoch + 1, epochs, loss_val_o, rank_val_o))\n",
    "    scheduler.step(loss_val_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea0ecea",
   "metadata": {},
   "source": [
    "## Loss and Rank metric visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e016eafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLotting the loss\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.arange(len(total_perepoch_loss)), total_perepoch_loss)\n",
    "plt.xlabel(\" epochs \")\n",
    "plt.ylabel(\" Contrastive loss for the epoch \")\n",
    "plt.title(\" Contrastive loss versus epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fecf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(\n",
    "    saving_dir +  \"/Contrastive_loss_prog_\" + str(dataset) + \"Emb_dim\" + str(\n",
    "        Embedding_dim) + \"_tau_\" + str(tau) + \"_batchsize_\" + str(\n",
    "        batchSize) + \"_epochs_\" + str(epochs) +  \".png\")\n",
    "plt.savefig(\n",
    "    saving_dir +  \"/Contrastive_loss_prog_\" + str(dataset) + \"Emb_dim\" + str(\n",
    "        Embedding_dim) + \"_tau_\" + str(tau) + \"_batchsize_\" + str(\n",
    "        batchSize) + \"_epochs_\" + str(epochs) +  \".pdf\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e796ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the rank metric\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.arange(len(total_perepoch_rank)), total_perepoch_rank)\n",
    "plt.xlabel(\" epochs \")\n",
    "plt.ylabel(\" Rank metric for the epoch \")\n",
    "plt.title(\" Rank metric when the batch size is \" + str(batchSize) + \"\\n Best rank value is batch size\")\n",
    "# plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd0d492",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(\n",
    "    saving_dir +  \"/Rank_metric_prog_\" + str(dataset) + \"Emb_dim\" + str(\n",
    "        Embedding_dim) + \"_tau_\" + str(tau) + \"_batchsize_\" + str(\n",
    "        batchSize) + \"_epochs_\" + str(epochs) +  \".png\")\n",
    "plt.savefig(\n",
    "    saving_dir +  \"/Rank_metric_prog_\" + str(dataset) + \"Emb_dim\" + str(\n",
    "        Embedding_dim) + \"_tau_\" + str(tau) + \"_batchsize_\" + str(\n",
    "        batchSize) + \"_epochs_\" + str(epochs) +  \".pdf\")\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
